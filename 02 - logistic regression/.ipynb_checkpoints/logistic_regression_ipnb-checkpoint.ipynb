{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 梯度下降法(gradient descent)\n",
    "下面的h(x)是要拟合的函数，J(theta)损失函数，theta是参数，要迭代求解的值，theta求解出来了那最终要拟合的函数h(theta)就出来了。其中m是训练集的记录条数，n是参数的个数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "h(\\theta) = \\sum\\limits_{j=0}^n\\theta_jx_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J(\\theta) = \\frac{1}{2m}\\sum\\limits_{i=1}^{m}(y^i-h_\\theta(x^i))^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（1）将J(theta)对theta求偏导，得到每个theta对应的的梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{\\partial J(\\theta)}{\\partial \\theta_j} = -\\frac{1}{m}\\sum\\limits_{i=1}^{m}(y^i-h_\\theta(x^i))x_j^i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "（2）由于是要最小化风险函数，所以按每个参数theta的梯度负方向，来更新每个theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\theta_j = \\theta_j + \\frac{\\partial J(\\theta)}{\\partial \\theta_j}\n",
    "$$\n",
    "即使  \n",
    "$$\n",
    "\\theta_j = \\theta_j + \\frac{1}{m}\\sum\\limits_{i=1}^{m}(y^i-h_\\theta(x^i))x_j^i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将以上公式改成向量形式的表达，以获取计算时的加速，以参数个数为2的时候为例\n",
    "$h(\\theta)$等价的说法是:  \n",
    "$$\n",
    "h = \\theta^Tx\n",
    "$$\n",
    "其中,\n",
    "$$\n",
    "\\theta = \n",
    "\\begin{pmatrix}\n",
    "\\theta_0\\\\\n",
    "\\theta_1\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "更新公式:\n",
    "$$\n",
    "\\theta = \\theta + \\alpha\\nabla_\\theta f(\\theta)\n",
    "$$\n",
    "其中  \n",
    "$$\n",
    "\\nabla _\\theta f(\\theta) = \n",
    "\\begin{pmatrix}\n",
    "\\frac{\\partial f(x,y)}{\\partial x}\\\\\n",
    "\\frac{\\partial f(x,y)}{\\partial y}\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "算法思想如下：  \n",
    "（1） 初始化回归系数  \n",
    "（2） 重复N次:  \n",
    "　　计算整个数据集的梯度  \n",
    "　　使用*alpha* x *gradient*更新回归系数的向量　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
